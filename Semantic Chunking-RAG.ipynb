{"cells":[{"cell_type":"code","execution_count":5,"id":"4b9d25c4-8282-48bb-9fb2-36c974ddd9d2","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:04:02.810240Z","iopub.status.busy":"2024-09-01T05:04:02.809712Z","iopub.status.idle":"2024-09-01T05:04:20.229420Z","shell.execute_reply":"2024-09-01T05:04:20.228210Z","shell.execute_reply.started":"2024-09-01T05:04:02.810203Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-09-01 05:04:04--  https://arxiv.org/pdf/1810.04805.pdf\n","Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.195.42, 151.101.131.42, ...\n","Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://arxiv.org/pdf/1810.04805 [following]\n","--2024-09-01 05:04:20--  http://arxiv.org/pdf/1810.04805\n","Connecting to arxiv.org (arxiv.org)|151.101.3.42|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 775166 (757K) [application/pdf]\n","Saving to: ‘1810.04805.pdf’\n","\n","1810.04805.pdf      100%[===================>] 757.00K  --.-KB/s    in 0.01s   \n","\n","2024-09-01 05:04:20 (64.3 MB/s) - ‘1810.04805.pdf’ saved [775166/775166]\n","\n"]}],"source":["! wget \"https://arxiv.org/pdf/1810.04805.pdf\""]},{"cell_type":"code","execution_count":10,"id":"477b5165-15be-4662-9597-e6dc4fd5652f","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:07:49.435477Z","iopub.status.busy":"2024-09-01T05:07:49.435142Z","iopub.status.idle":"2024-09-01T05:07:58.827103Z","shell.execute_reply":"2024-09-01T05:07:58.825630Z","shell.execute_reply.started":"2024-09-01T05:07:49.435451Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain-community in /opt/conda/lib/python3.11/site-packages (0.2.15)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (2.0.21)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (3.10.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.15 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.2.15)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.37 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.2.37)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.1.108)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (2.31.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.6)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.15->langchain-community) (0.2.2)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.15->langchain-community) (2.8.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (23.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (4.8.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.0.7)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2021.10.8)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.0rc3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (4.0.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.37->langchain-community) (2.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain-community) (2.20.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","Collecting pypdf\n","  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n","Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-4.3.1\n"]}],"source":["# Process the PDF Content\n","\n","!pip install langchain-community\n","!pip install pypdf\n","\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"]},{"cell_type":"code","execution_count":12,"id":"689ae052-f81c-4edf-9edd-c649aa5497e5","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:10:38.157827Z","iopub.status.busy":"2024-09-01T05:10:38.157524Z","iopub.status.idle":"2024-09-01T05:10:39.226324Z","shell.execute_reply":"2024-09-01T05:10:39.223276Z","shell.execute_reply.started":"2024-09-01T05:10:38.157802Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["16\n"]}],"source":["loader = PyPDFLoader(\"1810.04805.pdf\")\n","documents = loader.load()\n","print(len(documents))"]},{"cell_type":"code","execution_count":13,"id":"c462c41a-25e2-4cc5-89a2-c254dc15a86b","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:11:00.380950Z","iopub.status.busy":"2024-09-01T05:11:00.380550Z","iopub.status.idle":"2024-09-01T05:11:00.390254Z","shell.execute_reply":"2024-09-01T05:11:00.389463Z","shell.execute_reply.started":"2024-09-01T05:11:00.380913Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BERT BERT \n","E[CLS] E1 E[SEP] ... ENE1’... EM’\n","C\n","T1\n","T[SEP] ...\n"," TN\n","T1’...\n"," TM’\n","[CLS] Tok 1 [SEP] ... Tok NTok 1 ... TokM \n","Question Paragraph Start/End Span \n","BERT \n","E[CLS] E1 E[SEP] ... ENE1’... EM’\n","C\n","T1\n","T[SEP] ...\n"," TN\n","T1’...\n"," TM’\n","[CLS] Tok 1 [SEP] ... Tok NTok 1 ... TokM \n","Masked Sentence A Masked Sentence B \n","Pre-training Fine-Tuning NSP Mask LM Mask LM \n","Unlabeled Sentence A and B Pair SQuAD \n","Question Answer Pair NER MNLI Figure 1: Overall pre-training and ﬁne-tuning procedures for BERT. Apart from output layers, the same architec-\n","tures are used in both pre-training and ﬁne-tuning. The same pre-trained model parameters are used to initialize\n","models for different down-stream tasks. During ﬁne-tuning, all parameters are ﬁne-tuned. [CLS] is a special\n","symbol added in front of every input example, and [SEP] is a special separator token (e.g. separating ques-\n","tions/answers).\n","ing and auto-encoder objectives have been used\n","for pre-training such models (Howard and Ruder,\n","\n","2018; Radford et al., 2018; Dai and Le, 2015).\n","2.3 Transfer Learning from Supervised Data\n","There has also been work showing effective trans-\n","fer from supervised tasks with large datasets, such\n","as natural language inference (Conneau et al.,\n","2017) and machine translation (McCann et al.,\n","2017). Computer vision research has also demon-\n","strated the importance of transfer learning from\n","large pre-trained models, where an effective recipe\n","is to ﬁne-tune models pre-trained with Ima-\n","geNet (Deng et al., 2009; Yosinski et al., 2014).\n","3 BERT\n","We introduce BERT and its detailed implementa-\n","tion in this section. There are two steps in our\n","framework: pre-training and ﬁne-tuning . Dur-\n","ing pre-training, the model is trained on unlabeled\n","data over different pre-training tasks. For ﬁne-\n","tuning, the BERT model is ﬁrst initialized with\n","the pre-trained parameters, and all of the param-\n","eters are ﬁne-tuned using labeled data from the\n","downstream tasks. Each downstream task has sep-\n","\n","arate ﬁne-tuned models, even though they are ini-\n","tialized with the same pre-trained parameters. The\n","question-answering example in Figure 1 will serve\n","as a running example for this section.\n","A distinctive feature of BERT is its uniﬁed ar-\n","chitecture across different tasks. There is mini-mal difference between the pre-trained architec-\n","ture and the ﬁnal downstream architecture.\n","Model Architecture BERT’s model architec-\n","ture is a multi-layer bidirectional Transformer en-\n","coder based on the original implementation de-\n","scribed in Vaswani et al. (2017) and released in\n","thetensor2tensor library.1Because the use\n","of Transformers has become common and our im-\n","plementation is almost identical to the original,\n","we will omit an exhaustive background descrip-\n","tion of the model architecture and refer readers to\n","Vaswani et al. (2017) as well as excellent guides\n","such as “The Annotated Transformer.”2\n","In this work, we denote the number of layers\n","(i.e., Transformer blocks) as L, the hidden size as\n","\n","H, and the number of self-attention heads as A.3\n","We primarily report results on two model sizes:\n","BERT BASE (L=12, H=768, A=12, Total Param-\n","eters=110M) and BERT LARGE (L=24, H=1024,\n","A=16, Total Parameters=340M).\n","BERT BASE was chosen to have the same model\n","size as OpenAI GPT for comparison purposes.\n","Critically, however, the BERT Transformer uses\n","bidirectional self-attention, while the GPT Trans-\n","former uses constrained self-attention where every\n","token can only attend to context to its left.4\n","1https://github.com/tensorﬂow/tensor2tensor\n","2http://nlp.seas.harvard.edu/2018/04/03/attention.html\n","3In all cases we set the feed-forward/ﬁlter size to be 4H,\n","i.e., 3072 for the H= 768 and 4096 for the H= 1024 .\n","4We note that in the literature the bidirectional Trans-\n","\n","Input/Output Representations To make BERT\n","handle a variety of down-stream tasks, our input\n","representation is able to unambiguously represent\n","both a single sentence and a pair of sentences\n","(e.g.,⟨Question, Answer⟩) in one token sequence.\n","Throughout this work, a “sentence” can be an arbi-\n","trary span of contiguous text, rather than an actual\n","linguistic sentence. A “sequence” refers to the in-\n","put token sequence to BERT, which may be a sin-\n","gle sentence or two sentences packed together.\n","We use WordPiece embeddings (Wu et al.,\n","2016) with a 30,000 token vocabulary. The ﬁrst\n","token of every sequence is always a special clas-\n","siﬁcation token ( [CLS] ). The ﬁnal hidden state\n","corresponding to this token is used as the ag-\n","gregate sequence representation for classiﬁcation\n","tasks. Sentence pairs are packed together into a\n","single sequence. We differentiate the sentences in\n","two ways. First, we separate them with a special\n","token ( [SEP] ). Second, we add a learned embed-\n","\n"]}],"source":["#Perform Naive Chunking(RecursiveCharacterTextSplitting)\n","\n","\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=0,\n","    length_function=len,\n","    is_separator_regex=False\n",")\n","naive_chunks = text_splitter.split_documents(documents)\n","for chunk in naive_chunks[10:15]:\n","  print(chunk.page_content+ \"\\n\")"]},{"cell_type":"code","execution_count":15,"id":"cb5c3d25-b7f1-410c-8e4f-74cb0494c0d6","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:12:28.715853Z","iopub.status.busy":"2024-09-01T05:12:28.715245Z","iopub.status.idle":"2024-09-01T05:14:14.823025Z","shell.execute_reply":"2024-09-01T05:14:14.820062Z","shell.execute_reply.started":"2024-09-01T05:12:28.715820Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_51/1033616347.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n","  embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n","/opt/conda/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1ba87bd913b4abd9873d8e6010fd7c7","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"478123d2c4c34d04878f1969b4890a2a","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"507747662f4e41cc9dc931bca48e9b0c","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd54f1d70530427e9499eb4c8cf51cc9","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e45508582504a26bd884a29fd1717ac","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e0369ccdb6349e18f1c5e793fe1701d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e9f17bca1494998a48064bd659071a2","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"139d738a986c414e9de8fde46addf413","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aed7e0874d994a36a2fd016c25ffd1fe","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"542ab81899954bbbaf7047f7d8b292b5","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"172bbf6d608a4a96bce36b4a51761616","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#Instantiate Embedding Model\n","\n","!pip install sentence-transformers --quiet\n","\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"]},{"cell_type":"code","execution_count":28,"id":"9cc918f1-74ea-4ea6-bbf0-a0b069094cc7","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:24:24.940966Z","iopub.status.busy":"2024-09-01T05:24:24.940552Z","iopub.status.idle":"2024-09-01T05:24:30.103084Z","shell.execute_reply":"2024-09-01T05:24:30.096613Z","shell.execute_reply.started":"2024-09-01T05:24:24.940933Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: groq in /opt/conda/lib/python3.11/site-packages (0.10.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from groq) (4.0.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from groq) (0.27.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from groq) (2.8.2)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from groq) (1.3.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from groq) (4.8.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.3)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2021.10.8)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n"]}],"source":["#Setup the API Key for LLM\n","\n","!pip install groq\n","\n","#!pip install langchain\n","#!pip install langchain-groq. \n","from groq import Groq\n","#from langchain_groq import ChatGroq\n","\n","import os\n","\n","groq_api_key = os.getenv(\"Replace your API Key\")"]},{"cell_type":"code","execution_count":33,"id":"907b6dc5-c6a0-439e-b7cc-4bc1e40a8d9d","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:26:56.036659Z","iopub.status.busy":"2024-09-01T05:26:56.036262Z","iopub.status.idle":"2024-09-01T05:28:14.690717Z","shell.execute_reply":"2024-09-01T05:28:14.689832Z","shell.execute_reply.started":"2024-09-01T05:26:56.036625Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain_experimental in /opt/conda/lib/python3.11/site-packages (0.0.64)\n","Requirement already satisfied: langchain-community<0.3.0,>=0.2.10 in /opt/conda/lib/python3.11/site-packages (from langchain_experimental) (0.2.15)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /opt/conda/lib/python3.11/site-packages (from langchain_experimental) (0.2.37)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.21)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.6.7)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.15 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.15)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.1.108)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.31.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (23.2)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.8.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (4.8.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.9.6)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.4)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.15->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.7)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.7)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2021.10.8)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.0.0rc3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (4.0.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.14.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.0)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in /opt/conda/lib/python3.11/site-packages (from langchain-openai) (0.2.37)\n","Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n","  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (6.0.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (0.1.108)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (23.2)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (2.8.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (4.8.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.0.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.2)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n","  Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.1)\n","Collecting typing-extensions>=4.7 (from langchain-core<0.3.0,>=0.2.35->langchain-openai)\n","  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n","Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.3)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2021.10.8)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain-openai) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.35->langchain-openai) (3.10.7)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.35->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.35->langchain-openai) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.7)\n","Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n","Installing collected packages: typing-extensions, jiter, tiktoken, openai, langchain-openai\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.8.0\n","    Uninstalling typing_extensions-4.8.0:\n","      Successfully uninstalled typing_extensions-4.8.0\n","Successfully installed jiter-0.5.0 langchain-openai-0.1.23 openai-1.43.0 tiktoken-0.7.0 typing-extensions-4.12.2\n","Dev Set\n","Tasks MNLI-m QNLI MRPC SST-2 SQuAD\n","(Acc) (Acc) (Acc) (Acc) (F1)\n","BERT BASE 84.4 88.4 86.7 92.7 88.5\n","No NSP 83.9 84.9 86.5 92.6 87.9\n","LTR & No NSP 82.1 84.3 77.5 92.1 77.8\n","+ BiLSTM 82.1 84.1 75.7 91.6 84.9\n","Table 5: Ablation over the pre-training tasks using the\n","BERT BASE architecture. “No NSP” is trained without\n","the next sentence prediction task. “LTR & No NSP” is\n","trained as a left-to-right LM without the next sentence\n","prediction, like OpenAI GPT. “+ BiLSTM” adds a ran-\n","domly initialized BiLSTM on top of the “LTR + No\n","NSP” model during ﬁne-tuning. ablation studies can be found in Appendix C. 5.1 Effect of Pre-training Tasks\n","We demonstrate the importance of the deep bidi-\n","rectionality of BERT by evaluating two pre-\n","training objectives using exactly the same pre-\n","training data, ﬁne-tuning scheme, and hyperpa-\n","rameters as BERT BASE :\n","No NSP : A bidirectional model which is trained\n","using the “masked LM” (MLM) but without the\n","“next sentence prediction” (NSP) task. LTR & No NSP : A left-context-only model which\n","is trained using a standard Left-to-Right (LTR)\n","LM, rather than an MLM.\n","1097\n"]}],"source":["#Perform Semantic Chunking\n","\n","!pip install langchain_experimental\n","!pip install langchain-openai\n","\n","from langchain_experimental.text_splitter import SemanticChunker\n","from langchain_openai.embeddings import OpenAIEmbeddings\n","\n","semantic_chunker = SemanticChunker(embed_model, breakpoint_threshold_type=\"percentile\")\n","\n","semantic_chunks = semantic_chunker.create_documents([d.page_content for d in documents])\n","\n","for semantic_chunk in semantic_chunks:\n","  if \"Effect of Pre-training Tasks\" in semantic_chunk.page_content:\n","    print(semantic_chunk.page_content)\n","    print(len(semantic_chunk.page_content))"]},{"cell_type":"code","execution_count":34,"id":"0f962424-9765-42e3-96ef-f05c90917462","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:29:52.110438Z","iopub.status.busy":"2024-09-01T05:29:52.110006Z","iopub.status.idle":"2024-09-01T05:30:13.395061Z","shell.execute_reply":"2024-09-01T05:30:13.393975Z","shell.execute_reply.started":"2024-09-01T05:29:52.110398Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["#Store the chunks in our database\n","\n","!pip install singlestoredb --quiet\n","\n","\n","from langchain_community.vectorstores import SingleStoreDB\n","\n","semantic_chunk_vectorstore = SingleStoreDB.from_documents(semantic_chunks, embedding=embed_model)"]},{"cell_type":"code","execution_count":35,"id":"ae858e00-cebf-4230-ab6d-9d71f7f037ff","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:30:32.050038Z","iopub.status.busy":"2024-09-01T05:30:32.049155Z","iopub.status.idle":"2024-09-01T05:30:32.273488Z","shell.execute_reply":"2024-09-01T05:30:32.272817Z","shell.execute_reply.started":"2024-09-01T05:30:32.049999Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["[Document(page_content='The right part of the paper represents the\\nDev set results. For the feature-based approach,\\nwe concatenate the last 4 layers of BERT as the\\nfeatures, which was shown to be the best approach\\nin Section 5.3. From the table it can be seen that ﬁne-tuning is\\nsurprisingly robust to different masking strategies. However, as expected, using only the M ASK strat-\\negy was problematic when applying the feature-\\nbased approach to NER. Interestingly, using only\\nthe R NDstrategy performs much worse than our\\nstrategy as well.')]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["#Instantiate Retrieval Step\n","semantic_chunk_retriever = semantic_chunk_vectorstore.as_retriever(search_kwargs={\"k\" : 1})\n","semantic_chunk_retriever.invoke(\"Describe the Feature-based Approach with BERT?\")"]},{"cell_type":"code","execution_count":38,"id":"ac61cebd-c549-4e7e-8c21-3bf1f6f53061","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:31:10.356199Z","iopub.status.busy":"2024-09-01T05:31:10.355860Z","iopub.status.idle":"2024-09-01T05:31:10.361027Z","shell.execute_reply":"2024-09-01T05:31:10.360320Z","shell.execute_reply.started":"2024-09-01T05:31:10.356171Z"},"language":"python","trusted":true},"outputs":[],"source":["#Instantiate Augmentation Step(for content Augmentation)\n","\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","rag_template = \"\"\"\\\n","Use the following context to answer the user's query. If you cannot answer, please respond with 'I don't know'.\n","\n","User's Query:\n","{question}\n","\n","Context:\n","{context}\n","\"\"\"\n","\n","rag_prompt = ChatPromptTemplate.from_template(rag_template)"]},{"cell_type":"code","execution_count":54,"id":"a752f984-e27f-4b85-8894-205b4008ad02","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:46:01.245836Z","iopub.status.busy":"2024-09-01T05:46:01.245410Z","iopub.status.idle":"2024-09-01T05:46:06.920475Z","shell.execute_reply":"2024-09-01T05:46:06.918894Z","shell.execute_reply.started":"2024-09-01T05:46:01.245802Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain-groq in /opt/conda/lib/python3.11/site-packages (0.1.9)\n","Requirement already satisfied: groq<1,>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from langchain-groq) (0.10.0)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /opt/conda/lib/python3.11/site-packages (from langchain-groq) (0.2.37)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq) (4.0.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq) (2.8.2)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (6.0.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (0.1.108)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (23.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (8.5.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.3)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2021.10.8)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.10.7)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.31.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.0.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (1.26.7)\n"]}],"source":["#Instantiate the Generation Step\n","\n","# Define the userdata dictionary with your API key\n","!pip install langchain-groq\n","\n","#!pip install chat-groq\n","from langchain_groq import ChatGroq\n","userdata = {\n","    \"GROQ_API_KEY\": \"replace your API Key\"\n","}\n","\n","# Initialize the chat model\n","chat_model = ChatGroq(\n","    temperature=0,\n","    model_name=\"mixtral-8x7b-32768\",\n","    api_key=userdata.get(\"GROQ_API_KEY\")\n",")"]},{"cell_type":"code","execution_count":55,"id":"e24a8cc4-6951-40e7-a014-733c9760a704","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:46:14.685310Z","iopub.status.busy":"2024-09-01T05:46:14.684855Z","iopub.status.idle":"2024-09-01T05:46:14.692318Z","shell.execute_reply":"2024-09-01T05:46:14.691696Z","shell.execute_reply.started":"2024-09-01T05:46:14.685281Z"},"language":"python","trusted":true},"outputs":[],"source":["#RAG Pipeline Utilizing Semantic Chunking\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","\n","semantic_rag_chain = (\n","    {\"context\" : semantic_chunk_retriever, \"question\" : RunnablePassthrough()}\n","    | rag_prompt\n","    | chat_model\n","    | StrOutputParser()\n",")"]},{"cell_type":"code","execution_count":56,"id":"e8fdba9b-6d17-49c0-9b73-e99dd843660b","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:46:18.953190Z","iopub.status.busy":"2024-09-01T05:46:18.952840Z","iopub.status.idle":"2024-09-01T05:46:34.981065Z","shell.execute_reply":"2024-09-01T05:46:34.979732Z","shell.execute_reply.started":"2024-09-01T05:46:18.953162Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["'The Feature-based Approach with BERT involves concatenating the last 4 layers of BERT as features, which was found to be the most effective method in Section 5.3 of the paper. This approach is then compared in the table on the right side of the paper, which presents the Dev set results. Fine-tuning is shown to be robust to different masking strategies, but using only the MASK strategy is problematic when applying the feature-based approach to Named Entity Recognition (NER). Using only the RND strategy performs significantly worse than the proposed strategy.'"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["semantic_rag_chain.invoke(\"Describe the Feature-based Approach with BERT?\")"]},{"cell_type":"code","execution_count":57,"id":"0917c150-4119-4bc7-8745-8c7336b84f14","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:47:03.881901Z","iopub.status.busy":"2024-09-01T05:47:03.881539Z","iopub.status.idle":"2024-09-01T05:47:04.769567Z","shell.execute_reply":"2024-09-01T05:47:04.769053Z","shell.execute_reply.started":"2024-09-01T05:47:03.881861Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["'SQuAD v2.0, or Squad 2.0, is a version of the Stanford Question Answering Dataset (SQuAD) that extends the problem definition of SQuAD 1.1 by allowing for the possibility that no short answer exists in the provided paragraph. This makes the problem more realistic. To extend the SQuAD v1.1 BERT model for this task, questions that do not have an answer are treated as having an answer span with start and end at the [CLS] token. The probability space for the start and end answer span positions is extended to include the position of the [CLS] token. For prediction, the score of the no-answer span is compared to the score of the best non-null span. The TriviaQA data used for this task consists of paragraphs from TriviaQA-Wiki formed of the first 400 tokens in documents, that contain at least one of the provided possible answers.'"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["#Question 2\n","\n","semantic_rag_chain.invoke(\"What is SQuADv2.0?\")"]},{"cell_type":"code","execution_count":58,"id":"fed48fb5-62a1-4a3e-ab93-49db8b2f7411","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:47:21.354385Z","iopub.status.busy":"2024-09-01T05:47:21.354027Z","iopub.status.idle":"2024-09-01T05:47:21.932286Z","shell.execute_reply":"2024-09-01T05:47:21.931479Z","shell.execute_reply.started":"2024-09-01T05:47:21.354356Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["\"Ablation studies are used to understand the impact of different components or settings of a machine learning model on its performance. In the given context, ablation studies are used to answer specific questions about the BERT model's pre-training process.\\n\\nFor instance, one ablation study investigates the effect of the number of training steps on the MNLI Dev accuracy after fine-tuning. This helps determine whether BERT truly requires a large amount of pre-training to achieve high fine-tuning accuracy.\\n\\nAnother ablation study evaluates different masking procedures in BERT's pre-training with the masked language model (MLM) objective. This study aims to reduce the mismatch between pre-training and fine-tuning by comparing various masking strategies and their impact on MNLI and Named Entity Recognition (NER) Dev set results.\""]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["# Question 3\n","\n","semantic_rag_chain.invoke(\"What is the purpose of Ablation Studies?\")"]},{"cell_type":"code","execution_count":59,"id":"54950693-6d83-485c-ae81-1c1e9f8344bf","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:47:48.701004Z","iopub.status.busy":"2024-09-01T05:47:48.700627Z","iopub.status.idle":"2024-09-01T05:48:10.147977Z","shell.execute_reply":"2024-09-01T05:48:10.147063Z","shell.execute_reply.started":"2024-09-01T05:47:48.700976Z"},"language":"python","trusted":true},"outputs":[],"source":["#Implement a RAG pipeline using Naive Chunking Strategy\n","\n","naive_chunk_vectorstore = SingleStoreDB.from_documents(naive_chunks, embedding=embed_model)\n","naive_chunk_retriever = naive_chunk_vectorstore.as_retriever(search_kwargs={\"k\" : 5})\n","naive_rag_chain = (\n","    {\"context\" : naive_chunk_retriever, \"question\" : RunnablePassthrough()}\n","    | rag_prompt\n","    | chat_model\n","    | StrOutputParser()\n",")"]},{"cell_type":"code","execution_count":60,"id":"68230e7c-c63b-4e44-b940-0da0da081d5c","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:48:35.561068Z","iopub.status.busy":"2024-09-01T05:48:35.560579Z","iopub.status.idle":"2024-09-01T05:48:36.723720Z","shell.execute_reply":"2024-09-01T05:48:36.722790Z","shell.execute_reply.started":"2024-09-01T05:48:35.561038Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["'The Feature-based Approach with BERT involves extracting the activations from one or more layers of the pre-trained BERT model without fine-tuning any of its parameters. These contextual embeddings are then used as input to a separately initialized two-layer BiLSTM before the classification layer. In the context provided, the best performing feature-based method concatenates the token representations from the top four hidden layers of the pre-trained Transformer, achieving an F1 score of 94.6, which is only 0.3 behind fine-tuning the entire model. This demonstrates the effectiveness of BERT for feature-based approaches. The feature-based approach, as shown in Table 8, is surprisingly robust to different masking strategies during pre-training, but when applying it to Named Entity Recognition (NER), using only the MASK strategy proved problematic, and the RND strategy performed much worse than the strategy used in the study.'"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["# Question 1 \n","\n","naive_rag_chain.invoke(\"Describe the Feature-based Approach with BERT?\")"]},{"cell_type":"code","execution_count":62,"id":"661df2d3-8fe9-4bb2-90a2-7a9bee88f750","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:49:02.788951Z","iopub.status.busy":"2024-09-01T05:49:02.788583Z","iopub.status.idle":"2024-09-01T05:49:03.829928Z","shell.execute_reply":"2024-09-01T05:49:03.829138Z","shell.execute_reply.started":"2024-09-01T05:49:02.788922Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["'SQuAD v2.0, or the Stanford Question Answering Dataset version 2.0, is an extension of SQuAD 1.1 that allows for the possibility that no short answer exists in the provided paragraph. This makes the problem more realistic. To handle this, the SQuAD v1.1 BERT model is extended by treating questions without an answer as having an answer span with start and end at the [CLS] token. The probability space for the start and end answer span positions is extended to include the position of the [CLS] token. During prediction, the score of the no-answer span is compared to the score of the best non-null span. The document also mentions that the TriviaQA data they used consists of paragraphs from TriviaQA-Wiki formed of the first 400 tokens in documents, that contain at least one of the provided possible answers.'"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["# Question 2\n","naive_rag_chain.invoke(\"What is SQuADv2.0?\")"]},{"cell_type":"code","execution_count":63,"id":"e47de760-937a-4c9b-9a9a-0e0db68ad883","metadata":{"execution":{"iopub.execute_input":"2024-09-01T05:49:23.862036Z","iopub.status.busy":"2024-09-01T05:49:23.861649Z","iopub.status.idle":"2024-09-01T05:49:24.942024Z","shell.execute_reply":"2024-09-01T05:49:24.941455Z","shell.execute_reply.started":"2024-09-01T05:49:23.862006Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["'Ablation studies are used to evaluate the effect of different components or settings in a machine learning model. In the provided context, there are two ablation studies mentioned:\\n\\n1. Effect of Number of Training Steps: This study investigates how the number of training steps during pre-training affects the performance of the BERT model. The results show that BERT BASE achieves almost 1.0% additional accuracy on MNLI when trained on 1M steps compared to 500k steps.\\n\\n2. Ablation for Different Masking Procedures: This study evaluates the effect of different masking strategies used during pre-training with the masked language model (MLM) objective. The results show that the masking strategies aim to reduce the mismatch between pre-training and fine-tuning, and the choice of masking rates can impact the performance of the model on MNLI and NER tasks.\\n\\nIn summary, ablation studies help to understand the impact of different components or settings in a model, providing insights into the importance of each element and how they contribute to the overall performance.'"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["# Question 3\n","naive_rag_chain.invoke(\"What is the purpose of Ablation Studies?\")"]},{"cell_type":"code","execution_count":null,"id":"3e5b8490-2879-4fce-854c-6513fc1b8e0e","metadata":{"language":"python","trusted":true},"outputs":[],"source":[]}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"a0b60fe7-df21-48be-9184-0ac72a866f16","defaultDatabase":"db_pavan_8a031"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}
